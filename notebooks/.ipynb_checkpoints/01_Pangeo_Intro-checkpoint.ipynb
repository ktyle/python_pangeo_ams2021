{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Climate and Meteorology AMS Online Short Course 2021\n",
    "## Pangeo Notebook 01: Pangeo Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook and the two that follow, we will introduce you to the Pangeo project, in particular its focus on making datasets, large and small, accessible via cloud-based resources.\n",
    "Our learning goals are as follows. \n",
    "\n",
    "By the end of these notebooks you will have learned:\n",
    "\n",
    "1. An introduction to the Pangeo project\n",
    "2. How to open, analyze, and visualize cloud-served datasets\n",
    "3. Links to more information about Pangeo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pangeo and why should we care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [Pangeo](https://pangeo.io) website:\n",
    "\n",
    ">\"Pangeo is first and foremost a community promoting open, reproducible, and scalable science. This community provides documentation, develops and maintains software, and deploys computing infrastructure to make scientific research and programming easier. The Pangeo software ecosystem involves open source tools such as xarray, iris, dask, jupyter, and many other packages. There is no single software package called “pangeo”; rather, the Pangeo project serves as a coordination point between scientists, software, and computing infrastructure.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pangeo is motivated by the following recognized computing and data-centric problems found in (but certainly not unique to) the geosciences:\n",
    "1. Big Data: datasets are growing too rapidly and legacy software tools for scientific analysis can’t handle them. This is a major obstacle to scientific progress.\n",
    "\n",
    "2. Technology Gap: a growing gap between the technological sophistication of industry solutions (high) and scientific software (low).\n",
    "\n",
    "3. Reproducibility: a fragmentation of software tools and environments renders most geoscience research effectively unreproducible and prone to failure.\n",
    "\n",
    "Pangeo aims to address these challenges through a unified, collaborative effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the (very limited) amount of time we have today, we'll attempt via the three notebooks presented to address these three problems. Our main focus will be on accessing datasets, small and large, without actually downloading copies of them to our local machines and networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to open, analyze, and visualize cloud-served datasets\n",
    "\n",
    "The remainder of this notebook is based on [Notebook 3](https://github.com/xarray-contrib/xarray-tutorial/blob/master/scipy-tutorial/03_computation_with_xarray.ipynb) from the [Xarray Tutorial](https://github.com/xarray-contrib/xarray-tutorial/tree/master/scipy-tutorial) that was presented at the [SciPy 2020 conference](https://www.scipy2020.scipy.org/) this past July.\n",
    "### Small dataset (45 MB)\n",
    "First we load a relatively small dataset. We will use the\n",
    "[NOAA Extended Reconstructed Sea Surface Temperature (ERSST) v5](https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5)\n",
    "product, a widely used and trusted gridded compilation of of historical data\n",
    "going back to 1854.\n",
    "\n",
    "While the official archive data exists and is updated monthly at [NCEI](https://www.ncei.noaa.gov/pub/data/cmb/ersst/v5/netcdf) in NetCDF format, here we will access a subset covering 1960-2018 that is served in a Pangeo-maintained <i>storage bucket</i> via the Google Cloud Platform. It is in the new [Zarr data format](https://zarr.readthedocs.io/en/stable/), which is ideally-suited for what's called [object storage](https://www.networkcomputing.com/data-centers/storage-comparison-object-vs-file-vs-block-storage). Typically, large datafiles that are cloud-hosted in a <i>storage bucket</i> use the object storage model.\n",
    "Xarray will treat a dataset in Zarr format just as if it were in NetCDF format on a traditional block storage system.\n",
    "\n",
    "We use a method from the Google Cloud Services Python library to read in the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem()\n",
    "ds = xr.open_zarr(\n",
    "    fs.get_mapper(\"gs://pangeo-noaa-ncei/noaa.ersst.v5.zarr\"), consolidated=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Xarray's representation of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of this dataset is: %.3f GB\" % (ds.nbytes / 1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice that even though this dataset is in Zarr format as opposed to NetCDF, Xarray's representation looks the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataArray object that represents the data variable of interest from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = ds.sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine this `DataArray`. We can see that Xarray is treating it as a Dask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic visualizations of the data, just to make sure it looks\n",
    "reasonable. We'll select September, 1982 and choose a filled contour interval of -2 to 30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nino = sst.sel(time='12-01-1982')\n",
    "nino.plot(vmin=-2, vmax=30,figsize=(11,8.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nina = sst.sel(time='12-01-1983')\n",
    "nina.plot(vmin=-2, vmax=30,figsize=(11,8.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Arithmetic\n",
    "\n",
    "Xarray dataarrays (and by extension, Dask arrays) and datasets work seamlessly with arithmetic operators and\n",
    "numpy array functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: subtract the 1982 data from 1983 and plot the result. You should get a nice sense of the SST variation during an historically large transtion from El Niño to La Niña conditions in the Pacific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions\n",
    "\n",
    "Just as in NumPy and Pandas, we can reduce Xarray DataArrays along any number of axes. In Xarray, we can pass in whatever axis or multiple axes we want, using the `dim` keyword.\n",
    "1. Calculate the mean over all times. This returns a Dask array for each lat/lon coordinate pair in the Dataset (note, nothing has actually been computed yet!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.mean(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do a simple visualization of this 59-year mean. Doing the visualization triggers the computation of the mean from the Dask array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst.mean(dim='time').plot(figsize=(11,8.5), vmin=-2, vmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: What would the following cell produce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "This will produce just a single value (and strictly speaking, a single-valued `DataArray`) ... corresponding to the mean SST over all times and gridpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "Take the mean of `sst` in both longitude and latitude and make a simple timeseries plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All of the standard Numpy/Pandas reductions (e.g. `min`, `max`, `sum`, `std`, etc.) are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we have accessed, analyzed, and visualized data that is housed remotely without having to download a copy of it. While this particular dataset it trivial in terms of size, similar techniques will work effectively on much larger datasets. In the next couple of notebooks, we'll access CMIP6 and HRRR datasets stored in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interested in finding out more, and participating in, the Pangeo community? You are most welcome! Check out https://pangeo.io/about.html#get-involved, as well as the Blog, Forum, and other links on the main Pangeo site!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
